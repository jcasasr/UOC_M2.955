{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "        <img src=\"../figs/uoc_masterbrand_3linies_positiu.png\", align=\"left\">\n",
    "    </div>\n",
    "    <div style=\"float: right; width: 50%;\">\n",
    "        <p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Models avançats de mineria de dades</p>\n",
    "        <p style=\"margin: 0; text-align:right;\">Màster universitari en Ciència de dades (<i>Data science</i>)</p>\n",
    "        <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "    </div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufIapjtVdA5H"
   },
   "source": [
    "# Exemple de combinació de classificadors\n",
    "\n",
    "En aquest exemple compararem l'ús d'arbres de decisió i models _ensemble_, en concret, el model **Random Forest**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZVJdfCtEnHP"
   },
   "source": [
    "## Introducció\n",
    "\n",
    "L'_ensemble learning_ és una estratègia en què es fa servir un grup de models per resoldre un problema mitjançant la combinació estratègica de diversos models d'aprenentatge automàtic en un sol model predictiu. \n",
    "\n",
    "En general, els mètodes d'ensemble s'utilitzen principalment per millorar la precisió del rendiment general d'un model i per combinar diversos models diferents, també coneguts com a *aprenents bàsics*, per predir els resultats, en lloc d'utilitzar un sol model.\n",
    "\n",
    "Per què entrenem tants classificadors diferents en lloc d'un de sol? L'ús de diversos models per predir el resultat final en realitat redueix la probabilitat de sospesar les decisions preses per models deficients (sobreentrenats, no degudament ajustats, etc.).\n",
    "\n",
    "Com més diversos siguin aquests aprenents bàsics, més poderós serà el model final. \n",
    "\n",
    "Tinguem en compte que en qualsevol model d'aprenentatge automàtic, l'error de generalització ve donat per la suma de quadrats de biaix + variància + error irreductible. \n",
    "\n",
    "Els errors irreductibles són una cosa que va més enllà de nosaltres! No els podem reduir.\n",
    "\n",
    "Tot i això, utilitzant ensembles podem reduir el biaix (bias) i la variància d'un model. Això redueix l'error de generalització general.\n",
    "\n",
    "La **compensació de biaix-variància** és el punt de referència més important que diferencia un model robust d'un inferior (entenguem per inferior un model no gaire generalitzable). \n",
    "\n",
    "Tot i que no és una regla exacta, en l'aprenentatge automàtic, els models que tenen un biaix alt tendeixen a tenir una variància més baixa i viceversa.\n",
    "\n",
    "Hem estat parlant de biaix i variància. Però veiem què entenem per un biaix d'un model i per variància d'un model.\n",
    "\n",
    "1. **Biaix**: el biaix és un error que sorgeix a causa de suposicions falses realitzades en la fase d'aprenentatge d'un model. Un biaix alt pot fer que un algorisme d'aprenentatge ometi informació important i correlacions entre les variables independents i les etiquetes de classe, per la qual cosa no s'ajusta al model.\n",
    "\n",
    "2. **Variància**: la variància ens diu com de sensible és un model als petits canvis en les dades d'entrenament. És a dir, quant canvia el model. Una gran variació en un model el farà propens al soroll aleatori present al conjunt de dades, de manera que s'ajustarà massa al model.\n",
    "\n",
    "Per comprendre amb més detall la compensació de biaix i variància en els models d'aprenentatge automàtic, podeu consultar aquest [article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229). \n",
    "\n",
    "Un cop arribats a aquest punt, podem dividir els ensembles en quatre categories: \n",
    "\n",
    "1. **Bagging**: el bagging s'utilitza principalment per reduir la variació en un model. Un exemple simple de bagging és l'algorisme Random Forest.\n",
    "\n",
    "2. **Boosting**: el boosting s'utilitza principalment per reduir el biaix en un model. Exemples d'algorismes d'impuls són Ada-Boost, XGBoost, arbres de decisió millorats per gradient, etc.\n",
    "\n",
    "3. **Stacking**: el stacking s'utilitza principalment per augmentar la precisió de predicció d'un model. Per implementar l'stacking farem servir la biblioteca mlextend proporcionada per scikit learn.\n",
    "\n",
    "4. **Cascading**: aquesta classe de models són molt precisos. La connexió en cascada s'usa principalment en escenaris on no es pot permetre cometre un error. Per exemple, una tècnica en cascada es fa servir principalment per detectar transaccions fraudulentes amb targetes de crèdit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dades\n",
    "\n",
    "Per a aquest exercici farem servir el dataset *diabetes.csv*. Aquest conjunt de dades és original de l'Institut Nacional de Diabetis i Malalties Digestives i Renals. L'objectiu d'aquest dataset és predir, basant-nos en els mesuraments de diagnòstic, si un pacient té diabetis.\n",
    "\n",
    "En particular, tots els pacients són aquí dones d'almenys 21 anys, d'ascendència índia Pima.\n",
    "\n",
    "El dataset conté la següent informació\n",
    "\n",
    "- Embarassos: nombre d'embarassos\n",
    "- Glucosa: concentració de glucosa en plasma a 2 hores en una prova de tolerància a la glucosa oral\n",
    "- Pressió arterial: pressió arterial diastòlica (mm Hg)\n",
    "- SkinThickness: gruix del plec cutani del tríceps (mm)\n",
    "- Insulina: insulina sèrica de 2 hores (mu U / ml)\n",
    "- IMC: índex de massa corporal (pes en kg / (alçada en m) ^ 2)\n",
    "- DiabetesPedigreeFunction: funció del pedigrí de la diabetis\n",
    "- Edat: edat (anys)\n",
    "- Resultat (variable objectiu): variable de classe (0 o 1) \n",
    "\n",
    "A la primera part d'aquest exemple veurem la combinació de classificadors en paral·lel mitjançant les tècniques de **_Bagging_** i **_Boosting_**.\n",
    "\n",
    "Per començar, vegem com és el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "QVu-lXoK_L_d",
    "outputId": "c37bf1a4-895a-492f-e436-b806a0ed0bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 768 filas y 9 columnas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('../data/diabetes.csv')\n",
    "\n",
    "nRow, nCol = diabetes.shape\n",
    "print(f'Hi ha {nRow} files i {nCol} columnes')\n",
    "diabetes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTF33Hwv6fe-"
   },
   "source": [
    "Per poder provar diversos models, primer dividirem el dataset entre _train_ i _test_.\n",
    "\n",
    "Perquè tots obtingueu els mateixos resultats i poder comentar dubtes pel fòrum, fixarem la seed per obtenir els mateixos datasets de train i test.\n",
    "\n",
    "Com en aquest exercici tractarem *stacking* i *cascading*, i tots dos s'apliquen sobre el conjunt de test, farem un *split* del 60 % per tenir una mica més de base en aplicar aquestes dues tècniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "D97ORws3_-_5"
   },
   "outputs": [],
   "source": [
    "myseed= 38\n",
    "X = diabetes.drop(columns = 'Outcome')\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80Jw5L8A6fbu"
   },
   "source": [
    "## Combinació paral·lela de classificadors\n",
    "\n",
    "### 1. Arbres de decisió\n",
    "\n",
    "Per poder comparar l'augment de  *performance* obtingut a mesura que anem aplicant tècniques noves, utilitzarem com  *baseline* un simple arbre de decisió."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3daM2M6K6fYt"
   },
   "source": [
    "A continuació, entrenarem un arbre de decisió sobre el conjunt de dades de train amb profunditat màxima de 3 nivells (aplicarem la mateixa restricció a les següents seccions), i avaluarem sobre test i calcularem la seva precisió aplicant validació creuada amb 5 conjunts.\n",
    "   \n",
    "<u>Més informació</u>: \n",
    "- [*cross_val_score*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "- [*cross validation*](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pPRsy4NB8rW",
    "outputId": "241289af-08fb-49e7-fa8f-3072e312020b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media obtenida con CV: 71.04 +/- 4.82 %\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=myseed)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Precisió mitjana obtinguda amb CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8NMROHqCJn3",
    "outputId": "f843b664-e5f5-4129-e3ca-6d9ee3c1925c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462039045553145"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "accuracy_score(y_pred_tree, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lney04IhUuiQ"
   },
   "source": [
    "Obtenim una precisió en test no massa alta, una mica per sota de la de train (això pot variar depenent dels datasets de train i test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrUZJBCo6fTA"
   },
   "source": [
    "### 2. *Bagging*\n",
    "\n",
    "La idea central del bagging és fer servir rèpliques del conjunt de dades original i fer-les servir per entrenar diferents classificadors.\n",
    "\n",
    "Crearem subconjunts mostrant aleatòriament un munt de punts del conjunt de dades d'entrenament amb reemplaçament.\n",
    "\n",
    "Ara entrenarem classificadors individuals a cadascun d'aquests subconjunts bootstrap. \n",
    "\n",
    "Cada un d'aquests classificadors base predirà l'etiqueta de classe per a un problema donat. Aquí és on combinem les prediccions de tots els models base. Aquesta part s'anomena etapa d'agregació. És per això que trobareu els ensembles bagging pel nom d'ensembles d'agregació. \n",
    "\n",
    "En general, es fa servir un vot de majoria simple en un sistema de classificació i es pren la mitjana de totes les prediccions per als models de regressió per combinar tots els classificadors base en un sol model i proporcionar el resultat final del model de conjunt.\n",
    "\n",
    "Un exemple simple d'aquest enfocament és l'algorisme Random Forest. El bagging redueix l'alta variació (variança) d'un model, reduint així l'error de generalització. És un mètode molt eficaç, especialment quan tenim dades molt limitades com podria ser el nostre cas.\n",
    "\n",
    "Mitjançant l'ús de mostres de bootstrap, podem obtenir una estimació afegint les puntuacions de moltes mostres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RUXUdU16fP3"
   },
   "source": [
    "**Com faríem el bagging?**\n",
    "\n",
    "Suposem que tenim un conjunt d'entrenament que conté 100.000 punts de dades. \n",
    "\n",
    "Crearíem N subconjunts mostrejant a l'atzar 50K punts de dades per a cada subconjunt. \n",
    "\n",
    "Cadascun d'aquests N subconjunts s'utilitzarà per entrenar N classificadors diferents. \n",
    "\n",
    "A l'etapa d'agregació, totes aquestes N prediccions es combinaran en un sol model, també anomenat metaclassificador. \n",
    "\n",
    "Dels 100.000 punts presents originalment al conjunt de dades, si eliminem 1.000 punts, l'impacte que tindrà als conjunts de dades mostrades serà molt inferior.\n",
    "\n",
    "Si pensem intuïtivament, és possible que alguns d'aquests 1.000 punts no siguin presents a tots els conjunts de dades mostrejades i, per tant, la quantitat de punts que s'eliminaran de cada conjunt de dades mostrejades serà molt inferior. Fins i tot zero en alguns casos! En resum, l'impacte d'eliminar 1.000 punts d'aquest tipus serà en realitat menor als classificadors base, cosa que reduirà la variació en un model i el farà més sòlid. \n",
    "\n",
    "La variància no és més que sensibilitat al soroll, com hem comentat anteriorment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6rzIA586fMm"
   },
   "source": [
    "Seguidament, entrenarem un _**Random Forest**_ sobre el conjunt de dades de _train_ amb <b>20 arbres</b> de decisió i <b>profunditat màxima de 3</b> nivells, i avaluarem sobre test i calcularem la seva precisió aplicant una validació creuada amb 5 conjunts.\n",
    "\n",
    "<u>Més informació</u>: \n",
    "- [*RandomForestClassifier*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2ZC4x-mUXQu",
    "outputId": "47a70c8b-546e-4dc2-ca29-a4734a2b005f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media obtenida con CV: 73.29 +/- 1.57 %\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=20, max_depth=3, random_state=myseed)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Precisió mitjana obtinguda amb CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsP4btQ4Umbp",
    "outputId": "ca0f7a1c-8e73-4015-9f05-98fba510ebe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418655097613883"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_random_forest = clf.predict(X_test)\n",
    "accuracy_score(y_pred_random_forest, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvoCMkkuVMHF"
   },
   "source": [
    "Obtenim una bona precisió en test, una mica per sota de la de train. També notem una millora (encara que lleu) respecte a un simple arbre de decisió."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpMyZMpJZdE6"
   },
   "source": [
    "### 3. *Boosting*\n",
    "\n",
    "El _boosting_ s'utilitza per convertir els classificadors de base feble en forts. Els classificadors febles generalment tenen una correlació molt feble amb les etiquetes de classe veritables i els classificadors forts tenen una correlació molt alta entre el model i les etiquetes de classe veritables.\n",
    "\n",
    "El _boosting_ capacita els classificadors febles de manera iterativa, cadascun mirant de corregir l'error comès pel model anterior. Això s'aconsegueix entrenant un model feble en totes les dades d'entrenament, tot construint un segon model que té com a objectiu corregir els errors comesos pel primer model. Després construïm un tercer model que intenta corregir els errors comesos pel segon model i així successivament. Els models s'agreguen de manera iterativa fins que el model final ha corregit tots els errors comesos per tots els models anteriors.\n",
    "\n",
    "Quan s'afegeixen els models a cada etapa, s'assignen alguns pesos al model relacionat amb la precisió del model anterior. Després d'afegir un classificador feble, els pesos es tornen a ajustar. Els punts classificats incorrectament reben pesos més alts i els punts classificats correctament reben pesos més baixos. Aquest enfocament farà que el següent classificador se centri en els errors comesos pel model anterior.\n",
    "\n",
    "El boosting redueix l'error de generalització prenent un model d'alt biaix i baixa variància i reduint el biaix en un nivell significatiu. Recorda, el bagging redueix la variància. Com el bagging, el boosting també ens permet treballar amb models de classificació i regressió."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRIgEhOxZtVx"
   },
   "source": [
    "Entrenarem un _**Gradient Boosting**_ sobre el conjunt de dades de _train_ amb 20 arbres de decisió i profunditat màxima de 3 nivells. A continuació, avaluarem sobre test i calcularem la seva precisió aplicant una validació creuada amb 5 conjunts.\n",
    "\n",
    "<u>Més informació</u>: \n",
    "- [*GradientBoostingClassifier*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQjN6vxtaTWk",
    "outputId": "0c1fd372-4e23-4c9f-e568-814e6fedb16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media obtenida con CV: 72.00 +/- 4.23 %\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier(n_estimators=20, max_depth=3, random_state=myseed)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Precisió mitjana obtinguda amb CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAlyq1qAaa6k",
    "outputId": "486614b1-8f0d-4a47-dbc5-b37676a429d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635574837310195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_gradient_boosting = clf.predict(X_test)\n",
    "accuracy_score(y_pred_gradient_boosting, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "20211_M2.855_PEC4_Solucion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Tabla de contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.75px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.391px",
    "left": "1478px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
